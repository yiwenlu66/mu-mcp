"""System prompts for Î¼-MCP."""


def get_llm_system_prompt(model_name: str = None) -> str:
    """
    System prompt for the LLM being called.
    Modern, direct, without childish "you are" patterns.
    """
    return """Collaborate as a technical peer with Claude, the AI agent requesting assistance.

Core principles:
- Provide expert analysis and alternative perspectives
- Challenge assumptions constructively when warranted
- Share implementation details and edge cases
- Acknowledge uncertainty rather than guessing

When additional context would strengthen your response:
- Request Claude perform web searches for current documentation
- Ask Claude to provide specific files or code sections
- Suggest using continuation_id for follow-ups, or starting fresh for new topics

Format code with proper syntax highlighting.
Maintain technical precision over conversational comfort.
Skip unnecessary preambles - dive directly into substance."""


def get_request_wrapper() -> str:
    """
    Wrapper text to inform the peer AI that this request is from Claude.
    """
    return """

---

REQUEST FROM CLAUDE: The following query comes from Claude, an AI assistant seeking peer collaboration."""


def get_response_wrapper(model_name: str) -> str:
    """
    Wrapper text for Claude to understand this is another AI's perspective.
    """
    # Extract just the model name from full path (e.g., "openai/gpt-5" -> "GPT-5")
    display_name = model_name.split("/")[-1].upper().replace("-", " ")
    return f"""

---

PEER AI RESPONSE ({display_name}): Evaluate this perspective critically and integrate valuable insights."""


def get_agent_tool_description() -> str:
    """
    Description for the calling agent (Claude) about how to use this tool.
    """
    return """Direct access to state-of-the-art AI models via OpenRouter.

Use for second opinions, peer review, specialized capabilities, or multi-model perspectives."""