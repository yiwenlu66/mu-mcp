"""System prompts for Î¼-MCP."""


def get_llm_system_prompt(model_name: str = None) -> str:
    """
    System prompt for the LLM being called.
    Modern, direct, without childish "you are" patterns.
    """
    return """Collaborate as a technical peer with Claude, the AI agent requesting assistance.

Core principles:
- Provide expert analysis and alternative perspectives
- Challenge assumptions constructively when warranted
- Share implementation details and edge cases
- Acknowledge uncertainty rather than guessing

When additional context would strengthen your response:
- Request Claude perform web searches for current documentation
- Ask Claude to provide specific files or code sections

Format code with proper syntax highlighting.
Maintain technical precision over conversational comfort.
Skip unnecessary preambles - dive directly into substance."""


def get_request_wrapper() -> str:
    """
    Wrapper text to inform the peer AI that this request is from Claude.
    """
    return """

---

REQUEST FROM CLAUDE: The following query comes from Claude, an AI assistant seeking peer collaboration."""


def get_response_wrapper(model_name: str) -> str:
    """
    Wrapper text for Claude to understand this is another AI's perspective.
    
    Args:
        model_name: Short model name (e.g., "gpt-5", "sonnet")
    """
    # Format short name for display (e.g., "gpt-5" -> "GPT 5")
    display_name = model_name.upper().replace("-", " ")
    return f"""

---

PEER AI RESPONSE ({display_name}): Evaluate this perspective critically and integrate valuable insights."""


def get_agent_tool_description() -> str:
    """
    Description for the calling agent (Claude) about how to use this tool.
    """
    return """Direct access to state-of-the-art AI models via OpenRouter.

Provide EXACTLY ONE:
- title: Start fresh (when switching topics, context too long, or isolating model contexts)
- continuation_id: Continue existing conversation (preserves full context)

When starting fresh: Model has no context - include background details or attach files
When continuing: Model has conversation history - don't repeat context

FILE ATTACHMENT BEST PRACTICES:
- Proactively attach relevant files when starting new conversations for context
- For long content (git diffs, logs, terminal output), save to a file and attach it rather than pasting verbatim in prompt
- Files are processed more efficiently and precisely than inline text"""